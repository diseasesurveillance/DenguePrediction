x[1] <- rnorm(1)
for (i in 2:n) {
x_proposed <- rnorm(1, mean = x[i-1], sd = sqrt(sigma_squared))
alpha <- min(1, dnorm(x_proposed) / dnorm(x[i-1]))
if (runif(1) < alpha) {
x[i] <- x_proposed
} else {
x[i] <- x[i-1]
}
}
return(x)
}
n <- 10000
sigmas_squared <- c(0.15^2, 1, 2.4^2, 5^2)
results <- lapply(sigmas_squared, function(sigma_squared) {
metropolis_hastings_normal(n, sigma_squared)
})
par(mfrow = c(2, 2))
for (i in 1:length(results)) {
hist(results[[i]], main = paste("Sigma^2 =", sigmas_squared[i]), xlab = "Value", prob = TRUE)
lines(density(results[[i]]), col = "blue")
}
theta_prior_belief <- 0.4
alpha_prior_belief <- 3 #Pick a random number, say 3
beta_prior_belief <- 3*alpha_prior_belief/2
ggplot(prior_posterior_df, aes(x = Theta)) +
geom_line(aes(y = dbeta(theta_values,
shape1 = alpha_prior_belief,
shape2 = beta_prior_belief), color = "Prior")) +
geom_vline(xintercept = theta_prior_belief, linetype = "dashed") +
labs(title = "Prior Belief about Theta = 0.4",
x = expression(theta),
y = "Density") +
theme_minimal()
setwd('/Users/xiaoy0a/Desktop/course work/')
setwd('/Users/xiaoy0a/Desktop/course work/STAT240Bayesian')
setwd('/Users/xiaoy0a/Desktop/course work/STAT240Bayesian/Project 1')
x1 <- as.matrix(read.table("x1.txt"))
x2 <- as.matrix(read.table("x2.txt"))
y1 <- as.matrix(read.table("y1.txt"))
y2 <- as.matrix(read.table("y2.txt"))
x1 <- x1[1,]
y1 <- y1[1,]
normal_normal <- function(data, mean_like, prec_like, mean_prior, prec_prior){
prec_pose <- prec_prior + leng(data) + prec_like
mean_post <- (sum(data) * prec _ like + mean_prior * prec_prior)/prec_post
niter <- 10^5
x1 <- x1[1,]
abline(h = mean(trace[,i]))
setwd('/Users/xiaoy0a/Desktop/course work/STAT240Bayesian/Project 1')
x1 <- as.matrix(read.table("x1.txt"))
x2 <- as.matrix(read.table("x2.txt"))
y1 <- as.matrix(read.table("y1.txt"))
y2 <- as.matrix(read.table("y2.txt"))
x1 <- x1[1,]
y1 <- y1[1,]
normal_normal <- function(data, mean_like, prec_like, mean_prior, prec_prior){
prec_pose <- prec_prior + leng(data) + prec_like
mean_post <- (sum(data) * prec _ like + mean_prior * prec_prior)/prec_post
setwd('/Users/xiaoy0a/Desktop/course work/STAT240Bayesian/Project 1')
x1 <- as.matrix(read.table("x1.txt"))
x2 <- as.matrix(read.table("x2.txt"))
y1 <- as.matrix(read.table("y1.txt"))
y2 <- as.matrix(read.table("y2.txt"))
x1 <- x1[1,]
y1 <- y1[1,]
normal_normal <- function(data, mean_like, prec_like, mean_prior, prec_prior){
prec_pose <- prec_prior + leng(data) + prec_like
mean_post <- (sum(data) * prec_like + mean_prior * prec_prior)/prec_post
return(rnorm(1, mean = mean_post, sd = sqrt(1/prec_post)))
}
normal_gamma <- function( data, mean_like, prec_like, alpha, beta){
new_alpha <- alpha + length(data)/2
new_beta <- bate + sum((data-mean_like)^2)/2
return(rgamma(1,shape=new_alpha, rate=new_beta))
}
niter <- 10^5
burnin <- 10^4
nu_g <- mean(c(x1, y1))
delta_g <- 0
tau_g <- 1/var(c(x1, y1))
trace <- matrix(NA, nrow = niter, ncol = 3)
for(iter in 1:niter){
# Sampling nu_g
x1_new <- x1 - delta_g
y1_new <- y1 + delta_g
nu_g <- normal_normal(data = c(x1_new, y1_new),
mean_like = nu_g,
prec_like = tau_g,
mean_prior = 0,
prec_prior = 0.01)
# Sampleing delta_g
x1_new <- x1 - nu_g
y1_new <- y1 - nu_g
nu_g <- normal_normal(data = c(x1_new, y1_new),
mean_like = delta_g,
prec_like = tau_g,
mean_prior = 0,
prec_prior = 0.01)
# Sampling tau_g
tau_g <- normal_gamma(data = c(x1, y1),
mean_like = c(rep(nu_g + delta_g, length(x1)), rep(nu_g - delta_g, length(y1))),
prec_like = tau_g,
alpha = 0.01,
beta = 0.01)
trace[iter, ] <- c(nu_g, delta_g, tau_g)
}
abline(h = mean(trace[,i]))
for(i in 1:3){
plot(trace[,i], main = lable[i])
abline(h = mean(trace[,i]))
}
setwd('/Users/xiaoy0a/Desktop/course work/STAT240Bayesian/Project 1')
x1 <- as.matrix(read.table("x1.txt"))
x2 <- as.matrix(read.table("x2.txt"))
y1 <- as.matrix(read.table("y1.txt"))
y2 <- as.matrix(read.table("y2.txt"))
x1 <- x1[1,]
y1 <- y1[1,]
normal_normal <- function(data, mean_like, prec_like, mean_prior, prec_prior){
prec_pose <- prec_prior + leng(data) + prec_like
mean_post <- (sum(data) * prec_like + mean_prior * prec_prior)/prec_post
return(rnorm(1, mean = mean_post, sd = sqrt(1/prec_post)))
}
normal_gamma <- function( data, mean_like, prec_like, alpha, beta){
new_alpha <- alpha + length(data)/2
new_beta <- bate + sum((data-mean_like)^2)/2
return(rgamma(1,shape=new_alpha, rate=new_beta))
}
niter <- 10^5
burnin <- 10^4
nu_g <- mean(c(x1, y1))
delta_g <- 0
tau_g <- 1/var(c(x1, y1))
trace <- matrix(NA, nrow = niter, ncol = 3)
for(iter in 1:niter){
# Sampling nu_g
x1_new <- x1 - delta_g
y1_new <- y1 + delta_g
nu_g <- normal_normal(data = c(x1_new, y1_new),
mean_like = nu_g,
prec_like = tau_g,
mean_prior = 0,
prec_prior = 0.01)
# Sampleing delta_g
x1_new <- x1 - nu_g
y1_new <- y1 - nu_g
nu_g <- normal_normal(data = c(x1_new, y1_new),
mean_like = delta_g,
prec_like = tau_g,
mean_prior = 0,
prec_prior = 0.01)
# Sampling tau_g
tau_g <- normal_gamma(data = c(x1, y1),
mean_like = c(rep(nu_g + delta_g, length(x1)), rep(nu_g - delta_g, length(y1))),
prec_like = tau_g,
alpha = 0.01,
beta = 0.01)
trace[iter, ] <- c(nu_g, delta_g, tau_g)
}
normal_normal <- function(data, mean_like, prec_like, mean_prior, prec_prior){
prec_pose <- prec_prior + leng(data) + prec_like
mean_post <- (sum(data) * prec_like + mean_prior * prec_prior)/prec_post
return(rnorm(1, mean = mean_post, sd = sqrt(1/prec_post)))
}
normal_gamma <- function( data, mean_like, prec_like, alpha, beta){
new_alpha <- alpha + length(data)/2
new_beta <- bate + sum((data-mean_like)^2)/2
return(rgamma(1,shape=new_alpha, rate=new_beta))
}
niter <- 10^5
burnin <- 10^4
nu_g <- mean(c(x1, y1))
delta_g <- 0
tau_g <- 1/var(c(x1, y1))
trace <- matrix(NA, nrow = niter, ncol = 3)
for(iter in 1:niter){
# Sampling nu_g
x1_new <- x1 - delta_g
y1_new <- y1 + delta_g
nu_g <- normal_normal(data = c(x1_new, y1_new),
mean_like = nu_g,
prec_like = tau_g,
mean_prior = 0,
prec_prior = 0.01)
# Sampleing delta_g
x1_new <- x1 - nu_g
y1_new <- y1 - nu_g
nu_g <- normal_normal(data = c(x1_new, y1_new),
mean_like = delta_g,
prec_like = tau_g,
mean_prior = 0,
prec_prior = 0.01)
# Sampling tau_g
tau_g <- normal_gamma(data = c(x1, y1),
mean_like = c(rep(nu_g + delta_g, length(x1)), rep(nu_g - delta_g, length(y1))),
prec_like = tau_g,
alpha = 0.01,
beta = 0.01)
trace[iter, ] <- c(nu_g, delta_g, tau_g)
}
normal_normal <- function(data, mean_like, prec_like, mean_prior, prec_prior){
prec_pose <- prec_prior + length(data) + prec_like
mean_post <- (sum(data) * prec_like + mean_prior * prec_prior)/prec_post
return(rnorm(1, mean = mean_post, sd = sqrt(1/prec_post)))
}
for(iter in 1:niter){
# Sampling nu_g
x1_new <- x1 - delta_g
y1_new <- y1 + delta_g
nu_g <- normal_normal(data = c(x1_new, y1_new),
mean_like = nu_g,
prec_like = tau_g,
mean_prior = 0,
prec_prior = 0.01)
# Sampleing delta_g
x1_new <- x1 - nu_g
y1_new <- y1 - nu_g
nu_g <- normal_normal(data = c(x1_new, y1_new),
mean_like = delta_g,
prec_like = tau_g,
mean_prior = 0,
prec_prior = 0.01)
# Sampling tau_g
tau_g <- normal_gamma(data = c(x1, y1),
mean_like = c(rep(nu_g + delta_g, length(x1)), rep(nu_g - delta_g, length(y1))),
prec_like = tau_g,
alpha = 0.01,
beta = 0.01)
trace[iter, ] <- c(nu_g, delta_g, tau_g)
}
setwd('/Users/xiaoy0a/Desktop/course work/STAT240Bayesian/Project 1')
x1 <- as.matrix(read.table("x1.txt"))
x2 <- as.matrix(read.table("x2.txt"))
y1 <- as.matrix(read.table("y1.txt"))
y2 <- as.matrix(read.table("y2.txt"))
x1 <- x1[1,]
y1 <- y1[1,]
normal_normal <- function(data, mean_like, prec_like, mean_prior, prec_prior){
prec_pose <- prec_prior + length(data) + prec_like
mean_post <- (sum(data) * prec_like + mean_prior * prec_prior)/prec_post
return(rnorm(1, mean = mean_post, sd = sqrt(1/prec_post)))
}
normal_gamma <- function( data, mean_like, prec_like, alpha, beta){
new_alpha <- alpha + length(data)/2
new_beta <- bate + sum((data-mean_like)^2)/2
return(rgamma(1,shape=new_alpha, rate=new_beta))
}
niter <- 10^5
burnin <- 10^4
nu_g <- mean(c(x1, y1))
delta_g <- 0
tau_g <- 1/var(c(x1, y1))
trace <- matrix(NA, nrow = niter, ncol = 3)
for(iter in 1:niter){
# Sampling nu_g
x1_new <- x1 - delta_g
y1_new <- y1 + delta_g
nu_g <- normal_normal(data = c(x1_new, y1_new),
mean_like = nu_g,
prec_like = tau_g,
mean_prior = 0,
prec_prior = 0.01)
# Sampleing delta_g
x1_new <- x1 - nu_g
y1_new <- y1 - nu_g
nu_g <- normal_normal(data = c(x1_new, y1_new),
mean_like = delta_g,
prec_like = tau_g,
mean_prior = 0,
prec_prior = 0.01)
# Sampling tau_g
tau_g <- normal_gamma(data = c(x1, y1),
mean_like = c(rep(nu_g + delta_g, length(x1)), rep(nu_g - delta_g, length(y1))),
prec_like = tau_g,
alpha = 0.01,
beta = 0.01)
trace[iter, ] <- c(nu_g, delta_g, tau_g)
}
normal_normal <- function(data, mean_like, prec_like, mean_prior, prec_prior){
prec_post <- prec_prior + length(data) + prec_like
mean_post <- (sum(data) * prec_like + mean_prior * prec_prior)/prec_post
return(rnorm(1, mean = mean_post, sd = sqrt(1/prec_post)))
}
normal_gamma <- function( data, mean_like, prec_like, alpha, beta){
new_alpha <- alpha + length(data)/2
new_beta <- bate + sum((data-mean_like)^2)/2
return(rgamma(1,shape=new_alpha, rate=new_beta))
}
setwd('/Users/xiaoy0a/Desktop/course work/STAT240Bayesian/Project 1')
x1 <- as.matrix(read.table("x1.txt"))
y1 <- as.matrix(read.table("y1.txt"))
x1 <- x1[1,]
y1 <- y1[1,]
normal_normal <- function(data, mean_like, prec_like, mean_prior, prec_prior){
prec_post <- prec_prior + length(data) + prec_like
mean_post <- (sum(data) * prec_like + mean_prior * prec_prior)/prec_post
return(rnorm(1, mean = mean_post, sd = sqrt(1/prec_post)))
}
normal_gamma <- function( data, mean_like, prec_like, alpha, beta){
new_alpha <- alpha + length(data)/2
new_beta <- bate + sum((data-mean_like)^2)/2
return(rgamma(1,shape=new_alpha, rate=new_beta))
}
niter <- 10^5
burnin <- 10^4
nu_g <- mean(c(x1, y1))
delta_g <- 0
tau_g <- 1/var(c(x1, y1))
trace <- matrix(NA, nrow = niter, ncol = 3)
for(iter in 1:niter){
# Sampling nu_g
x1_new <- x1 - delta_g
y1_new <- y1 + delta_g
nu_g <- normal_normal(data = c(x1_new, y1_new),
mean_like = nu_g,
prec_like = tau_g,
mean_prior = 0,
prec_prior = 0.01)
# Sampleing delta_g
x1_new <- x1 - nu_g
y1_new <- y1 - nu_g
nu_g <- normal_normal(data = c(x1_new, y1_new),
mean_like = delta_g,
prec_like = tau_g,
mean_prior = 0,
prec_prior = 0.01)
# Sampling tau_g
tau_g <- normal_gamma(data = c(x1, y1),
mean_like = c(rep(nu_g + delta_g, length(x1)), rep(nu_g - delta_g, length(y1))),
prec_like = tau_g,
alpha = 0.01,
beta = 0.01)
trace[iter, ] <- c(nu_g, delta_g, tau_g)
}
normal_gamma <- function( data, mean_like, prec_like, alpha, beta){
new_alpha <- alpha + length(data)/2
new_beta <- bata + sum((data-mean_like)^2)/2
return(rgamma(1,shape=new_alpha, rate=new_beta))
}
setwd('/Users/xiaoy0a/Desktop/course work/STAT240Bayesian/Project 1')
x1 <- as.matrix(read.table("x1.txt"))
y1 <- as.matrix(read.table("y1.txt"))
x1 <- x1[1,]
y1 <- y1[1,]
normal_normal <- function(data, mean_like, prec_like, mean_prior, prec_prior){
prec_post <- prec_prior + length(data) + prec_like
mean_post <- (sum(data) * prec_like + mean_prior * prec_prior)/prec_post
return(rnorm(1, mean = mean_post, sd = sqrt(1/prec_post)))
}
normal_gamma <- function( data, mean_like, prec_like, alpha, beta){
new_alpha <- alpha + length(data)/2
new_beta <- beta + sum((data-mean_like)^2)/2
return(rgamma(1,shape=new_alpha, rate=new_beta))
}
niter <- 10^5
burnin <- 10^4
nu_g <- mean(c(x1, y1))
delta_g <- 0
tau_g <- 1/var(c(x1, y1))
trace <- matrix(NA, nrow = niter, ncol = 3)
for(iter in 1:niter){
# Sampling nu_g
x1_new <- x1 - delta_g
y1_new <- y1 + delta_g
nu_g <- normal_normal(data = c(x1_new, y1_new),
mean_like = nu_g,
prec_like = tau_g,
mean_prior = 0,
prec_prior = 0.01)
# Sampleing delta_g
x1_new <- x1 - nu_g
y1_new <- y1 - nu_g
nu_g <- normal_normal(data = c(x1_new, y1_new),
mean_like = delta_g,
prec_like = tau_g,
mean_prior = 0,
prec_prior = 0.01)
# Sampling tau_g
tau_g <- normal_gamma(data = c(x1, y1),
mean_like = c(rep(nu_g + delta_g, length(x1)), rep(nu_g - delta_g, length(y1))),
prec_like = tau_g,
alpha = 0.01,
beta = 0.01)
trace[iter, ] <- c(nu_g, delta_g, tau_g)
}
trace <- trace[-(1:burnin), ]
lable <- c("nu_g", "delta_g", "tau_g")
par(mfrow = c(3,2))
for(i in 1:3){
plot(trace[,i], main = lable[i])
abline(h = mean(trace[,i]))
}
label <- c("nu_g", "delta_g", "tau_g")
par(mfrow = c(3,2))
for(i in 1:3){
plot(trace[,i], main = label[i])
abline(h = mean(trace[,i]), col = "red")
hist(trace[,i], main = label[i])
}
setwd('/Users/xiaoy0a/Desktop/course work/STAT240Bayesian/Project 1')
x1 <- as.matrix(read.table("x1.txt"))
y1 <- as.matrix(read.table("y1.txt"))
x1 <- x1[1,]
y1 <- y1[1,]
normal_normal <- function(data, mean_like, prec_like, mean_prior, prec_prior){
prec_post <- prec_prior + length(data) + prec_like
mean_post <- (sum(data) * prec_like + mean_prior * prec_prior)/prec_post
return(rnorm(1, mean = mean_post, sd = sqrt(1/prec_post)))
}
normal_gamma <- function( data, mean_like, prec_like, alpha, beta){
new_alpha <- alpha + length(data)/2
new_beta <- beta + sum((data-mean_like)^2)/2
return(rgamma(1,shape=new_alpha, rate=new_beta))
}
niter <- 10^5
burnin <- 10^4
nu_g <- mean(c(x1, y1))
delta_g <- 0
tau_g <- 1/var(c(x1, y1))
trace <- matrix(NA, nrow = niter, ncol = 3)
for(iter in 1:niter){
# Sampling nu_g
x1_new <- x1 - delta_g
y1_new <- y1 + delta_g
nu_g <- normal_normal(data = c(x1_new, y1_new),
mean_like = nu_g,
prec_like = tau_g,
mean_prior = 0,
prec_prior = 0.01)
# Sampleing delta_g
x1_new <- x1 - nu_g
y1_new <- y1 - nu_g
delta_g <- normal_normal(data = c(x1_new, y1_new),
mean_like = delta_g,
prec_like = tau_g,
mean_prior = 0,
prec_prior = 0.01)
# Sampling tau_g
tau_g <- normal_gamma(data = c(x1, y1),
mean_like = c(rep(nu_g + delta_g, length(x1)), rep(nu_g - delta_g, length(y1))),
prec_like = tau_g,
alpha = 0.01,
beta = 0.01)
trace[iter, ] <- c(nu_g, delta_g, tau_g)
}
trace <- trace[-(1:burnin), ]
label <- c("nu_g", "delta_g", "tau_g")
par(mfrow = c(3,2))
for(i in 1:3){
plot(trace[,i], main = label[i])
abline(h = mean(trace[,i]), col = "red")
hist(trace[,i], main = label[i])
}
knitr::opts_chunk$set(echo = TRUE)
devtools::install_github("diseasesurveillance/denguetracker")
library(denguetracker)
# Set directory
setwd('/Users/xiaoy0a/Desktop/Task/Nowcasting/2ndMeeting/')
knitr::opts_chunk$set(echo = TRUE)
#devtools::install_github("diseasesurveillance/denguetracker")
library(denguetracker)
# Set directory
setwd('/Users/xiaoy0a/Desktop/Task/Nowcasting/2ndMeeting/')
knitr::opts_chunk$set(echo = TRUE)
data("municipalities")
#Now test 4 states with different features
# AC <- fetch_data_from_state("AC", 2013, 2023)
# AM <- fetch_data_from_state("AM", 2013, 2023)
# RJ <- fetch_data_from_state("RJ", 2013, 2023)
# SP <- fetch_data_from_state("SP", 2013, 2023)
#
# write.csv(AC,"AC.csv", row.names = F)
# write.csv(AM,"AM.csv", row.names = F)
# write.csv(RJ,"RJ.csv", row.names = F)
# write.csv(SP,"SP.csv", row.names = F)
AC <- read.csv("AC.csv")
# Google Trends data
colnames_GT <- c("Time", "Dengue", "Sintomas.dengue")
AC_GT <- read.csv("AC_GT.csv", header = F, col.names = colnames_GT
)[-c(1:3),]
AM_GT <- read.csv("AM_GT.csv", header = F, col.names = colnames_GT
)[-c(1:3),]
RJ_GT <- read.csv("RJ_GT.csv", header = F, col.names = colnames_GT
)[-c(1:3),]
SP_GT <- read.csv("SP_GT.csv", header = F, col.names = colnames_GT
)[-c(1:3),]
AC_GT_Weekly <- read.csv("AC_GT_Weekly.csv", header = F, col.names = colnames_GT
)[-c(1:3),]
AM_GT_Weekly <- read.csv("AM_GT_Weekly.csv", header = F, col.names = colnames_GT
)[-c(1:3),]
RJ_GT_Weekly <- read.csv("RJ_GT_Weekly.csv", header = F, col.names = colnames_GT
)[-c(1:3),]
SP_GT_Weekly <- read.csv("SP_GT_Weekly.csv", header = F, col.names = colnames_GT
)[-c(1:3),]
setwd('/Users/xiaoy0a/Desktop/Task/Nowcasting/DengueARGO')
devtools::document()
devtools::build(path = "/Users/xiaoy0a/Desktop/Task/Nowcasting/DengueARGO")
devtools::build(path = "/Users/xiaoy0a/Desktop/Task/Nowcasting/DengueARGO/")
devtools::build(path = "/Users/xiaoy0a/Desktop/Task/Nowcasting/DengueARGO/")
getwd
setwd('/Users/xiaoy0a/Desktop/Task/Nowcasting/DengueARGO')
getwd
devtools::document()
knitr::opts_chunk$set(echo = TRUE)
# 如果没有 {usethis} 包的话，先下载安装。
install.packages("usethis")
# 命名一个 {rPackageTutorial} 包，并且创建，path 可以填写你想创建在哪个文件夹中。
# 这里我们选择在当前路径创建该包
usethis::create_package(path = "rPackageTutorial")
getwd
setwd('/Users/xiaoy0a/Desktop/Task/Nowcasting/R_package/')
